// æ–‡ä»¶è·¯å¾„: packages/common-backend/src/ai/multimodal-examples.ts
// èŒè´£: VCPToolBox å¤šæ¨¡æ€æ•°æ®é“¾çš„ä½¿ç”¨ç¤ºä¾‹
// å±•ç¤ºBase64ç›´é€šè½¦ã€å…¨å±€æ–‡ä»¶APIã€è·¨æ¨¡æ€æ™ºèƒ½è½¬è¯‘

import { MultimodalDataType, type MultimodalService } from './multimodal.service'

/**
 * VCPToolBox å¤šæ¨¡æ€æ•°æ®é“¾ä½¿ç”¨ç¤ºä¾‹
 */
export class MultimodalExamples {
  constructor(private readonly multimodalService: MultimodalService) {}

  /**
   * ç¤ºä¾‹1: Base64ç›´é€šè½¦
   * åœºæ™¯: AIç›´æ¥åœ¨toolå­—æ®µä¸­ä¼ é€’Base64ç¼–ç çš„å¤šæ¨¡æ€æ•°æ®
   */
  async exampleBase64Pipeline() {
    console.log('ğŸš— Base64ç›´é€šè½¦ç¤ºä¾‹')
    console.log('')

    // æ¨¡æ‹ŸAIåœ¨toolè°ƒç”¨ä¸­ä¼ é€’çš„Base64å›¾åƒæ•°æ®
    const imageBase64 =
      'data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNkYPhfDwAChAI9jU77yQAAAABJRU5ErkJggg=='
    const mimeType = 'image/png'

    console.log('ğŸ“¥ æ¥æ”¶åˆ°AIä¼ é€’çš„Base64æ•°æ®...')
    console.log(`ç±»å‹: ${mimeType}`)
    console.log(`æ•°æ®é•¿åº¦: ${imageBase64.length} å­—ç¬¦`)
    console.log('')

    // å¤„ç†Base64æ•°æ®
    const multimodalData = this.multimodalService.processBase64Data(
      imageBase64.split(',')[1], // ç§»é™¤data URLå‰ç¼€
      mimeType,
      {
        filename: 'ai_generated_image.png',
        source: 'dall_e_ai',
        autoDetectType: true,
      }
    )

    console.log('ğŸ”„ å¤„ç†ç»“æœ:')
    console.log(`æ£€æµ‹ç±»å‹: ${multimodalData.type}`)
    console.log(`æ–‡ä»¶å¤§å°: ${multimodalData.metadata?.size} å­—èŠ‚`)
    console.log(`æ¥æº: ${multimodalData.source}`)
    console.log('')

    // åœ¨åç»­å¤„ç†ä¸­ä½¿ç”¨
    const processedResult = await this.processMultimodalData(multimodalData)
    console.log('ğŸ¯ åç»­å¤„ç†ç»“æœ:', processedResult)
    console.log('')

    return { multimodalData, processedResult }
  }

  /**
   * ç¤ºä¾‹2: å…¨å±€æ–‡ä»¶API v4.0
   * åœºæ™¯: åˆ†å¸ƒå¼èŠ‚ç‚¹é—´çš„æ–‡ä»¶å…±äº«å’Œè®¿é—®
   */
  async exampleGlobalFileApi() {
    console.log('ğŸŒ å…¨å±€æ–‡ä»¶API v4.0 ç¤ºä¾‹')
    console.log('')

    // åˆ›å»ºä¸€äº›æµ‹è¯•æ–‡ä»¶
    console.log('ğŸ“ åˆ›å»ºæµ‹è¯•æ–‡ä»¶...')
    await this.multimodalService.executeFileApi({
      action: 'write',
      path: 'documents/research_paper.pdf',
      data: {
        type: MultimodalDataType.FILE,
        content: Buffer.from('PDF content...'),
        metadata: {
          mimeType: 'application/pdf',
          filename: 'research_paper.pdf',
          size: 1024,
        },
      },
    })

    await this.multimodalService.executeFileApi({
      action: 'write',
      path: 'images/screenshot.png',
      data: {
        type: MultimodalDataType.IMAGE,
        content:
          'iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNkYPhfDwAChAI9jU77yQAAAABJRU5ErkJggg==',
        metadata: {
          mimeType: 'image/png',
          filename: 'screenshot.png',
        },
      },
    })

    console.log('âœ… æµ‹è¯•æ–‡ä»¶åˆ›å»ºå®Œæˆ')
    console.log('')

    // åˆ—å‡ºç›®å½•å†…å®¹
    console.log('ğŸ“‚ åˆ—å‡ºç›®å½•å†…å®¹...')
    const listResult = await this.multimodalService.executeFileApi({
      action: 'list',
      path: 'documents/',
    })

    if (listResult.success && listResult.data) {
      const fileList = JSON.parse(listResult.data.content as string)
      console.log('æ–‡æ¡£ç›®å½•æ–‡ä»¶:')
      fileList.files.forEach((file: any) => {
        console.log(`  - ${file.name} (${file.type})`)
      })
    }
    console.log('')

    // è¯»å–æ–‡ä»¶ï¼ˆæ¨¡æ‹Ÿåˆ†å¸ƒå¼è®¿é—®ï¼‰
    console.log('ğŸ“– è¯»å–æ–‡ä»¶...')
    const readResult = await this.multimodalService.executeFileApi({
      action: 'read',
      path: 'documents/research_paper.pdf',
    })

    if (readResult.success && readResult.data) {
      console.log(`æˆåŠŸè¯»å–æ–‡ä»¶: ${readResult.data.metadata?.filename}`)
      console.log(`æ–‡ä»¶å¤§å°: ${readResult.data.metadata?.size} å­—èŠ‚`)
    }
    console.log('')

    // æ¼”ç¤ºVCPè·¯å¾„è¯­æ³•
    console.log('ğŸ”— VCPè·¯å¾„è¯­æ³•ç¤ºä¾‹...')
    try {
      const vcpPath = 'H:\\MCP\\123.txt'
      const parsed = this.multimodalService.parseVcpPath(vcpPath)
      console.log(`VCPè·¯å¾„: ${vcpPath}`)
      console.log(`è§£æç»“æœ: èŠ‚ç‚¹=${parsed.nodeId}, è·¯å¾„=${parsed.filePath}`)
    } catch (error) {
      console.log(`è·¯å¾„è§£æé”™è¯¯:`, error instanceof Error ? error.message : String(error))
    }
    console.log('')

    return { listResult, readResult }
  }

  /**
   * ç¤ºä¾‹3: è·¨æ¨¡æ€æ™ºèƒ½è½¬è¯‘
   * åœºæ™¯: é«˜é˜¶æ¨¡å‹èƒ½åŠ›èµ‹èƒ½ä½é˜¶æ¨¡å‹ï¼Œè‡ªåŠ¨è¿›è¡Œæ¨¡æ€è½¬æ¢
   */
  async exampleCrossModalConversion() {
    console.log('ğŸ”„ è·¨æ¨¡æ€æ™ºèƒ½è½¬è¯‘ç¤ºä¾‹')
    console.log('')

    // å‡†å¤‡æµ‹è¯•æ•°æ®
    const testCases = [
      {
        name: 'è¯­éŸ³è½¬æ–‡å­—',
        sourceData: {
          type: MultimodalDataType.AUDIO,
          content: Buffer.from('mock audio data'),
          metadata: { mimeType: 'audio/wav' },
        } as any,
        targetType: MultimodalDataType.TEXT,
      },
      {
        name: 'å›¾åƒè½¬æè¿°',
        sourceData: {
          type: MultimodalDataType.IMAGE,
          content:
            'iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNkYPhfDwAChAI9jU77yQAAAABJRU5ErkJggg==',
          metadata: { mimeType: 'image/png' },
        } as any,
        targetType: MultimodalDataType.TEXT,
      },
      {
        name: 'æ–‡å­—è½¬è¯­éŸ³',
        sourceData: {
          type: MultimodalDataType.TEXT,
          content: 'ä½ å¥½ï¼Œä¸–ç•Œï¼',
          metadata: { language: 'zh-CN' },
        } as any,
        targetType: MultimodalDataType.AUDIO,
      },
    ]

    const results = []

    for (const testCase of testCases) {
      console.log(`ğŸ¯ æµ‹è¯•: ${testCase.name}`)
      console.log(`   æºç±»å‹: ${testCase.sourceData.type}`)
      console.log(`   ç›®æ ‡ç±»å‹: ${testCase.targetType}`)

      try {
        const result = await this.multimodalService.performCrossModalConversion({
          sourceData: testCase.sourceData,
          targetType: testCase.targetType,
          options: {
            language: 'zh-CN',
            quality: 0.9,
          },
        })

        if (result.success) {
          console.log(`   âœ… è½¬æ¢æˆåŠŸ`)
          console.log(`   è½¬æ¢è·¯å¾„: ${result.conversionPath.join(' â†’ ')}`)
          console.log(`   å¤„ç†æ—¶é—´: ${result.processingTime}ms`)
          console.log(`   ç½®ä¿¡åº¦: ${result.confidence}`)
          console.log(`   ç»“æœé¢„è§ˆ: ${this.previewData(result.convertedData)}`)
        } else {
          console.log(`   âŒ è½¬æ¢å¤±è´¥: ${result.error}`)
        }
      } catch (error) {
        console.log(`   âŒ è½¬æ¢å¼‚å¸¸:`, error instanceof Error ? error.message : String(error))
      }

      console.log('')
    }

    return results
  }

  /**
   * ç¤ºä¾‹4: åœ¨AIå·¥å…·è°ƒç”¨ä¸­çš„é›†æˆä½¿ç”¨
   * åœºæ™¯: AIè°ƒç”¨å·¥å…·æ—¶ä¼ é€’å¤šæ¨¡æ€æ•°æ®
   */
  async exampleAiToolIntegration() {
    console.log('ğŸ¤– AIå·¥å…·è°ƒç”¨å¤šæ¨¡æ€é›†æˆç¤ºä¾‹')
    console.log('')

    // æ¨¡æ‹ŸAIç”Ÿæˆçš„å†…å®¹ï¼ŒåŒ…å«å¤šæ¨¡æ€æ•°æ®
    const aiGeneratedContent = {
      text: 'æˆ‘åˆ†æäº†è¿™å¼ å›¾ç‰‡ï¼Œå‘ç°...',
      image:
        'data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNkYPhfDwAChAI9jU77yQAAAABJRU5ErkJggg==',
      audio:
        'data:audio/wav;base64,UklGRnoGAABXQVZFZm10IBAAAAABAAEARKwAAIhYAQACABAAAABkYXRhAgAAAAEA',
    }

    console.log('ğŸ“¥ AIç”Ÿæˆçš„å†…å®¹:')
    console.log(`æ–‡æœ¬: ${aiGeneratedContent.text}`)
    console.log(`å›¾åƒ: ${aiGeneratedContent.image.substring(0, 50)}...`)
    console.log(`éŸ³é¢‘: ${aiGeneratedContent.audio.substring(0, 50)}...`)
    console.log('')

    // å¤„ç†æ¯ä¸ªæ¨¡æ€çš„æ•°æ®
    const processedData = []

    // å¤„ç†å›¾åƒ
    const imageData = this.multimodalService.processBase64Data(
      aiGeneratedContent.image.split(',')[1],
      'image/png',
      { source: 'ai_generation' }
    )
    processedData.push(imageData)

    // å¤„ç†éŸ³é¢‘
    const audioData = this.multimodalService.processBase64Data(
      aiGeneratedContent.audio.split(',')[1],
      'audio/wav',
      { source: 'ai_generation' }
    )
    processedData.push(audioData)

    console.log('ğŸ”„ å¤„ç†ç»“æœ:')
    processedData.forEach((data, index) => {
      console.log(`  ${index + 1}. ç±»å‹: ${data.type}, å¤§å°: ${data.metadata?.size} å­—èŠ‚`)
    })
    console.log('')

    // ä¿å­˜åˆ°åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ
    console.log('ğŸ’¾ ä¿å­˜åˆ°åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ...')
    for (let i = 0; i < processedData.length; i++) {
      const data = processedData[i]
      const filePath = `ai_generated/${data.type}_${i + 1}.${this.getExtension(data.type)}`

      await this.multimodalService.executeFileApi({
        action: 'write',
        path: filePath,
        data,
      })

      console.log(`   ä¿å­˜: ${filePath}`)
    }
    console.log('')

    // æ¼”ç¤ºè·¨æ¨¡æ€è½¬æ¢
    console.log('ğŸ”„ æ‰§è¡Œè·¨æ¨¡æ€è½¬æ¢...')
    const conversionTasks = [
      {
        source: processedData[0], // å›¾åƒ
        target: MultimodalDataType.TEXT,
        description: 'å›¾åƒè½¬æ–‡å­—æè¿°',
      },
      {
        source: processedData[1], // éŸ³é¢‘
        target: MultimodalDataType.TEXT,
        description: 'éŸ³é¢‘è½¬æ–‡å­—è½¬å†™',
      },
    ]

    for (const task of conversionTasks) {
      const result = await this.multimodalService.performCrossModalConversion({
        sourceData: task.source,
        targetType: task.target,
      })

      console.log(`${task.description}:`)
      if (result.success) {
        console.log(`   âœ… ${this.previewData(result.convertedData)}`)
      } else {
        console.log(`   âŒ å¤±è´¥: ${result.error}`)
      }
    }
    console.log('')

    return { aiGeneratedContent, processedData }
  }

  /**
   * ç¤ºä¾‹5: æµå¼å¤šæ¨¡æ€æ•°æ®å¤„ç†
   * åœºæ™¯: å¤„ç†å¤§å‹å¤šæ¨¡æ€æ•°æ®æµ
   */
  async exampleStreamingMultimodal() {
    console.log('ğŸŒŠ æµå¼å¤šæ¨¡æ€æ•°æ®å¤„ç†ç¤ºä¾‹')
    console.log('')

    // åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®æµ
    async function* createMockDataStream(): AsyncIterable<Buffer> {
      const chunks = [
        Buffer.from('Chunk 1: Header data...'),
        Buffer.from('Chunk 2: Main content...'),
        Buffer.from('Chunk 3: Metadata...'),
        Buffer.from('Chunk 4: Footer...'),
      ]

      for (const chunk of chunks) {
        yield chunk
        // æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
        await new Promise((resolve) => setTimeout(resolve, 100))
      }
    }

    console.log('ğŸ“¡ åˆ›å»ºå¤šæ¨¡æ€æ•°æ®æµ...')
    const dataStream = this.multimodalService.createMultimodalStream(
      createMockDataStream(),
      MultimodalDataType.FILE
    )

    console.log('ğŸ”„ å¤„ç†æ•°æ®æµ...')
    let chunkCount = 0
    for await (const chunk of dataStream) {
      chunkCount++
      console.log(
        `   æ¥æ”¶åˆ°å— ${chunkCount}: ${chunk.metadata?.chunkIndex}, å¤§å°: ${chunk.content.length} å­—èŠ‚`
      )
    }

    console.log(`âœ… æµå¤„ç†å®Œæˆï¼Œå…±å¤„ç† ${chunkCount} ä¸ªæ•°æ®å—`)
    console.log('')

    return { chunkCount }
  }

  /**
   * ç¤ºä¾‹6: è·å–æ”¯æŒçš„è½¬æ¢ç±»å‹
   */
  async exampleSupportedConversions() {
    console.log('ğŸ“‹ æ”¯æŒçš„æ¨¡æ€è½¬æ¢ç±»å‹')
    console.log('')

    const conversions = this.multimodalService.getSupportedConversions()

    conversions.forEach((conv) => {
      console.log(`${conv.from} â†’ æ”¯æŒè½¬æ¢åˆ°:`)
      conv.to.forEach((target) => {
        console.log(`  - ${target}: ${conv.description}`)
      })
      console.log('')
    })

    return conversions
  }

  // ===== è¾…åŠ©æ–¹æ³• =====

  private async processMultimodalData(data: any): Promise<string> {
    // æ¨¡æ‹Ÿæ•°æ®å¤„ç†é€»è¾‘
    return `å¤„ç†äº† ${data.type} ç±»å‹çš„æ•°æ®ï¼Œå¤§å° ${data.metadata?.size} å­—èŠ‚`
  }

  private previewData(data: any): string {
    if (data.type === MultimodalDataType.TEXT) {
      return `${(data.content as string).substring(0, 50)}...`
    } else if (typeof data.content === 'string' && data.content.length > 50) {
      return `${data.content.substring(0, 50)}...`
    } else {
      return `æ•°æ®ç±»å‹: ${data.type}, å¤§å°: ${data.metadata?.size || 'æœªçŸ¥'} å­—èŠ‚`
    }
  }

  private getExtension(type: MultimodalDataType): string {
    switch (type) {
      case MultimodalDataType.IMAGE:
        return 'png'
      case MultimodalDataType.AUDIO:
        return 'wav'
      case MultimodalDataType.VIDEO:
        return 'mp4'
      case MultimodalDataType.FILE:
        return 'bin'
      default:
        return 'dat'
    }
  }
}

/**
 * ä½¿ç”¨æŒ‡å—
 *
 * 1. å¯¼å…¥æœåŠ¡:
 * import { MultimodalService, MultimodalDataType } from './multimodal.service';
 *
 * 2. Base64ç›´é€šè½¦:
 * const data = multimodalService.processBase64Data(base64String, mimeType, options);
 *
 * 3. å…¨å±€æ–‡ä»¶API:
 * const result = await multimodalService.executeFileApi({
 *   action: 'read',
 *   path: 'nodeId:/path/to/file',
 * });
 *
 * 4. è·¨æ¨¡æ€è½¬æ¢:
 * const result = await multimodalService.performCrossModalConversion({
 *   sourceData: source,
 *   targetType: MultimodalDataType.TEXT,
 * });
 *
 * 5. VCPè·¯å¾„è§£æ:
 * const { nodeId, filePath } = multimodalService.parseVcpPath('H:\\MCP\\123.txt');
 *
 * 6. æµå¼å¤„ç†:
 * const stream = multimodalService.createMultimodalStream(dataIterator, type);
 * for await (const chunk of stream) { ... }
 *
 * ä¼˜åŠ¿:
 * - ğŸš— Base64ç›´é€š: AIå¯ç›´æ¥ä¼ é€’å¤šæ¨¡æ€æ•°æ®ï¼Œæ— éœ€é¢å¤–ç¼–ç 
 * - ğŸŒ åˆ†å¸ƒå¼æ–‡ä»¶: èŠ‚ç‚¹é—´æ— ç¼æ–‡ä»¶å…±äº«
 * - ğŸ”„ æ™ºèƒ½è½¬æ¢: è‡ªåŠ¨æ¨¡æ€è½¬æ¢ï¼Œæ‰“ç ´æ•°æ®å£å’
 * - ğŸ“¡ æµå¼å¤„ç†: æ”¯æŒå¤§å‹æ•°æ®çš„é«˜æ•ˆå¤„ç†
 */
